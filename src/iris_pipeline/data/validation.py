import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
from enum import Enum
import logging

# C·∫•u h√¨nh logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataType(Enum):
    """Enum cho c√°c ki·ªÉu d·ªØ li·ªáu ƒë∆∞·ª£c h·ªó tr·ª£"""
    NUMERIC = "numeric"
    CATEGORICAL = "categorical"
    BOOLEAN = "boolean"
    DATE = "date"

@dataclass
class ColumnSchema:
    """Schema cho t·ª´ng c·ªôt d·ªØ li·ªáu"""
    name: str
    data_type: DataType
    required: bool = True
    min_value: Optional[float] = None
    max_value: Optional[float] = None
    allowed_values: Optional[List[Any]] = None
    null_allowed: bool = False
    description: str = ""

class DataValidator:
    """Class ƒë·ªÉ validation d·ªØ li·ªáu"""
    
    def __init__(self, schema: List[ColumnSchema]):
        self.schema = {col.name: col for col in schema}
        self.validation_results = []
        
    def validate_dataframe(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Validate to√†n b·ªô DataFrame
        
        Args:
            df: DataFrame c·∫ßn validate
            
        Returns:
            Dict ch·ª©a k·∫øt qu·∫£ validation
        """
        logger.info("B·∫Øt ƒë·∫ßu validation d·ªØ li·ªáu...")
        
        results = {
            'is_valid': True,
            'errors': [],
            'warnings': [],
            'summary': {
                'total_rows': len(df),
                'total_columns': len(df.columns),
                'schema_columns': len(self.schema)
            }
        }
        
        # Ki·ªÉm tra c·ªôt b·∫Øt bu·ªôc
        missing_columns = set(self.schema.keys()) - set(df.columns)
        if missing_columns:
            error_msg = f"Thi·∫øu c√°c c·ªôt b·∫Øt bu·ªôc: {list(missing_columns)}"
            results['errors'].append(error_msg)
            results['is_valid'] = False
            logger.error(error_msg)
            
        # Ki·ªÉm tra c·ªôt th·ª´a
        extra_columns = set(df.columns) - set(self.schema.keys())
        if extra_columns:
            warning_msg = f"C√≥ c√°c c·ªôt kh√¥ng mong mu·ªën: {list(extra_columns)}"
            results['warnings'].append(warning_msg)
            logger.warning(warning_msg)
            
        # Validate t·ª´ng c·ªôt
        for col_name, col_schema in self.schema.items():
            if col_name in df.columns:
                series = df[col_name]
                assert isinstance(series, pd.Series)
                col_results = self._validate_column(series, col_schema)
                if col_results['errors']:
                    results['errors'].extend(col_results['errors'])
                    results['is_valid'] = False
                if col_results['warnings']:
                    results['warnings'].extend(col_results['warnings'])
                    
        # Ki·ªÉm tra data types
        type_results = self._validate_data_types(df)
        if type_results['errors']:
            results['errors'].extend(type_results['errors'])
            results['is_valid'] = False
            
        # Ki·ªÉm tra duplicates
        duplicate_results = self._check_duplicates(df)
        if duplicate_results['warnings']:
            results['warnings'].extend(duplicate_results['warnings'])
            
        logger.info(f"Validation ho√†n th√†nh. K·∫øt qu·∫£: {'PASS' if results['is_valid'] else 'FAIL'}")
        return results
    
    def _validate_column(self, series: pd.Series, schema: ColumnSchema) -> Dict[str, List[str]]:
        """Validate m·ªôt c·ªôt c·ª• th·ªÉ"""
        results = {'errors': [], 'warnings': []}
        col_name = schema.name
        
        # Ki·ªÉm tra null values
        null_count = series.isnull().sum()
        if null_count > 0:
            if not schema.null_allowed:
                results['errors'].append(f"C·ªôt '{col_name}' c√≥ {null_count} gi√° tr·ªã null kh√¥ng ƒë∆∞·ª£c ph√©p")
            else:
                results['warnings'].append(f"C·ªôt '{col_name}' c√≥ {null_count} gi√° tr·ªã null")
                
        # Ch·ªâ validate d·ªØ li·ªáu kh√¥ng null
        non_null_series = series.dropna()
        if len(non_null_series) == 0:
            return results
            
        # Ki·ªÉm tra range cho numeric data
        if schema.data_type == DataType.NUMERIC:
            if schema.min_value is not None:
                below_min = (non_null_series < schema.min_value).sum()
                if below_min > 0:
                    results['errors'].append(f"C·ªôt '{col_name}' c√≥ {below_min} gi√° tr·ªã < {schema.min_value}")
                    
            if schema.max_value is not None:
                above_max = (non_null_series > schema.max_value).sum()
                if above_max > 0:
                    results['errors'].append(f"C·ªôt '{col_name}' c√≥ {above_max} gi√° tr·ªã > {schema.max_value}")
                    
        # Ki·ªÉm tra allowed values
        if schema.allowed_values is not None:
            invalid_values = set(non_null_series.unique()) - set(schema.allowed_values)
            if invalid_values:
                results['errors'].append(f"C·ªôt '{col_name}' c√≥ gi√° tr·ªã kh√¥ng h·ª£p l·ªá: {list(invalid_values)}")
                
        return results
    
    def _validate_data_types(self, df: pd.DataFrame) -> Dict[str, List[str]]:
        """Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c c·ªôt"""
        results = {'errors': []}
        
        for col_name, col_schema in self.schema.items():
            if col_name not in df.columns:
                continue
                
            column = df[col_name]
            
            if col_schema.data_type == DataType.NUMERIC:
                if not pd.api.types.is_numeric_dtype(column):
                    results['errors'].append(f"C·ªôt '{col_name}' ph·∫£i l√† ki·ªÉu s·ªë")
                    
            elif col_schema.data_type == DataType.CATEGORICAL:
                if not pd.api.types.is_object_dtype(column):
                    results['errors'].append(f"C·ªôt '{col_name}' ph·∫£i l√† ki·ªÉu categorical/string")
                    
        return results
    
    def _check_duplicates(self, df: pd.DataFrame) -> Dict[str, List[str]]:
        """Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p"""
        results = {'warnings': []}
        
        duplicate_count = df.duplicated().sum()
        if duplicate_count > 0:
            results['warnings'].append(f"C√≥ {duplicate_count} h√†ng tr√πng l·∫∑p trong d·ªØ li·ªáu")
            
        return results
    
    def generate_report(self, validation_results: Dict[str, Any]) -> str:
        """T·∫°o b√°o c√°o validation"""
        report = []
        report.append("=" * 60)
        report.append("B√ÅO C√ÅO VALIDATION D·ªÆ LI·ªÜU")
        report.append("=" * 60)
        
        # Th√¥ng tin t·ªïng quan
        summary = validation_results['summary']
        report.append(f"T·ªïng s·ªë h√†ng: {summary['total_rows']}")
        report.append(f"T·ªïng s·ªë c·ªôt: {summary['total_columns']}")
        report.append(f"C·ªôt theo schema: {summary['schema_columns']}")
        
        # K·∫øt qu·∫£ validation
        status = "‚úÖ PASS" if validation_results['is_valid'] else "‚ùå FAIL"
        report.append(f"K·∫øt qu·∫£: {status}")
        
        # L·ªói
        if validation_results['errors']:
            report.append(f"\nüö® L·ªñI ({len(validation_results['errors'])} l·ªói):")
            for i, error in enumerate(validation_results['errors'], 1):
                report.append(f"  {i}. {error}")
                
        # C·∫£nh b√°o
        if validation_results['warnings']:
            report.append(f"\n‚ö†Ô∏è  C·∫¢NH B√ÅO ({len(validation_results['warnings'])} c·∫£nh b√°o):")
            for i, warning in enumerate(validation_results['warnings'], 1):
                report.append(f"  {i}. {warning}")
                
        report.append("=" * 60)
        return "\n".join(report)

# Schema cho d·ªØ li·ªáu Iris
IRIS_SCHEMA = [
    ColumnSchema(
        name="SepalLengthCm",
        data_type=DataType.NUMERIC,
        min_value=0.0,
        max_value=10.0,
        description="Chi·ªÅu d√†i ƒë√†i hoa (cm)"
    ),
    ColumnSchema(
        name="SepalWidthCm",
        data_type=DataType.NUMERIC,
        min_value=0.0,
        max_value=10.0,
        description="Chi·ªÅu r·ªông ƒë√†i hoa (cm)"
    ),
    ColumnSchema(
        name="PetalLengthCm",
        data_type=DataType.NUMERIC,
        min_value=0.0,
        max_value=10.0,
        description="Chi·ªÅu d√†i c√°nh hoa (cm)"
    ),
    ColumnSchema(
        name="PetalWidthCm",
        data_type=DataType.NUMERIC,
        min_value=0.0,
        max_value=10.0,
        description="Chi·ªÅu r·ªông c√°nh hoa (cm)"
    ),
    ColumnSchema(
        name="Species",
        data_type=DataType.CATEGORICAL,
        allowed_values=["Iris-setosa", "Iris-versicolor", "Iris-virginica"],
        description="Lo√†i hoa iris"
    )
]

def validate_iris_data(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Validate d·ªØ li·ªáu Iris
    
    Args:
        df: DataFrame ch·ª©a d·ªØ li·ªáu Iris
        
    Returns:
        Dict ch·ª©a k·∫øt qu·∫£ validation
    """
    validator = DataValidator(IRIS_SCHEMA)
    return validator.validate_dataframe(df)

def main():
    """Demo validation"""
    print("=" * 60)
    print("DEMO DATA VALIDATION")
    print("=" * 60)
    
    # ƒê·ªçc d·ªØ li·ªáu
    try:
        df = pd.read_csv('data/Iris.csv')
        print(f"‚úì ƒê·ªçc d·ªØ li·ªáu th√†nh c√¥ng: {df.shape}")
        
        # Lo·∫°i b·ªè c·ªôt Id n·∫øu c√≥
        if 'Id' in df.columns:
            df = df.drop('Id', axis=1)
            print("‚úì ƒê√£ lo·∫°i b·ªè c·ªôt Id")
            
        # Validate d·ªØ li·ªáu
        results = validate_iris_data(df)
        
        # T·∫°o validator v√† generate report
        validator = DataValidator(IRIS_SCHEMA)
        report = validator.generate_report(results)
        print(report)
        
        # Th·ªëng k√™ chi ti·∫øt
        print("\nüìä TH·ªêNG K√ä CHI TI·∫æT:")
        print(f"Ki·ªÉu d·ªØ li·ªáu c√°c c·ªôt:")
        for col in df.columns:
            print(f"  {col}: {df[col].dtype}")
            
        print(f"\nMissing values:")
        missing = df.isnull().sum()
        for col in missing.index:
            print(f"  {col}: {missing[col]}")
            
        print(f"\nGi√° tr·ªã unique:")
        for col in df.columns:
            if df[col].dtype == 'object':
                unique_vals = df[col].unique()
                print(f"  {col}: {list(unique_vals)}")
            else:
                print(f"  {col}: {df[col].nunique()} gi√° tr·ªã unique")
                
    except FileNotFoundError:
        print("‚ùå Kh√¥ng t√¨m th·∫•y file data/Iris.csv")
        return
    
    print("\n" + "=" * 60)
    print("HO√ÄN TH√ÄNH VALIDATION")
    print("=" * 60)

if __name__ == "__main__":
    main() 