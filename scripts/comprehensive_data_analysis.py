#!/usr/bin/env python3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import warnings
warnings.filterwarnings('ignore')

# C·∫•u h√¨nh style cho bi·ªÉu ƒë·ªì
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

class ComprehensiveDataAnalysis:
    """Ph√¢n t√≠ch d·ªØ li·ªáu to√†n di·ªán v·ªõi nhi·ªÅu lo·∫°i bi·ªÉu ƒë·ªì"""
    
    def __init__(self, data_path='data/Iris.csv'):
        """Kh·ªüi t·∫°o v·ªõi ƒë∆∞·ªùng d·∫´n d·ªØ li·ªáu"""
        self.data_path = data_path
        self.df = None
        self.numeric_features = None
        self.categorical_features = None
        
    def load_data(self):
        """T·∫£i d·ªØ li·ªáu"""
        print("="*80)
        print("üìä PH√ÇN T√çCH D·ªÆ LI·ªÜU IRIS TO√ÄN DI·ªÜN")
        print("="*80)
        
        try:
            self.df = pd.read_csv(self.data_path)
            print(f"‚úÖ D·ªØ li·ªáu ƒë√£ t·∫£i th√†nh c√¥ng: {self.df.shape[0]} m·∫´u, {self.df.shape[1]} c·ªôt")
            print(f"üìã C√°c c·ªôt: {list(self.df.columns)}")
            
            # Ph√¢n lo·∫°i features
            self.numeric_features = self.df.select_dtypes(include=[np.number]).columns.tolist()
            self.categorical_features = self.df.select_dtypes(include=['object']).columns.tolist()
            
            print(f"üî¢ Features s·ªë: {self.numeric_features}")
            print(f"üìù Features ph√¢n lo·∫°i: {self.categorical_features}")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
            return False
        
        return True
    
    def basic_info(self):
        """Th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu"""
        print("\n" + "="*50)
        print("üìã TH√îNG TIN C∆† B·∫¢N")
        print("="*50)
        
        # Th√¥ng tin t·ªïng quan
        print("\nüìä Th√¥ng tin t·ªïng quan:")
        print(self.df.info())
        
        # Th·ªëng k√™ m√¥ t·∫£
        print("\nüìà Th·ªëng k√™ m√¥ t·∫£:")
        print(self.df.describe())
        
        # Ki·ªÉm tra missing values
        print("\nüîç Ki·ªÉm tra missing values:")
        missing_data = self.df.isnull().sum()
        if missing_data.sum() == 0:
            print("‚úÖ Kh√¥ng c√≥ missing values")
        else:
            print("‚ö†Ô∏è C√≥ missing values:")
            print(missing_data[missing_data > 0])
        
        # Ph√¢n b·ªë c√°c l·ªõp
        print("\nüå∏ Ph√¢n b·ªë c√°c lo√†i:")
        species_counts = self.df['Species'].value_counts()
        print(species_counts)
        
        # T·ª∑ l·ªá ph·∫ßn trƒÉm
        print("\nüìä T·ª∑ l·ªá ph·∫ßn trƒÉm:")
        species_percent = self.df['Species'].value_counts(normalize=True) * 100
        for species, percent in species_percent.items():
            print(f"  {species}: {percent:.1f}%")
    
    def distribution_analysis(self):
        """Ph√¢n t√≠ch ph√¢n b·ªë d·ªØ li·ªáu"""
        print("\n" + "="*50)
        print("üìä PH√ÇN T√çCH PH√ÇN B·ªê")
        print("="*50)
        
        # Lo·∫°i b·ªè c·ªôt Id
        features = [col for col in self.numeric_features if col != 'Id']
        
        # T·∫°o subplot cho ph√¢n b·ªë
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('üìä Ph√¢n b·ªë c√°c ƒë·∫∑c tr∆∞ng', fontsize=16, fontweight='bold')
        
        for i, feature in enumerate(features):
            row, col = i // 2, i % 2
            ax = axes[row, col]
            
            # Histogram v·ªõi KDE
            for species in self.df['Species'].unique():
                subset = self.df[self.df['Species'] == species][feature]
                ax.hist(subset, alpha=0.6, label=species, bins=15, density=True)
            
            # KDE curve
            for species in self.df['Species'].unique():
                subset = self.df[self.df['Species'] == species][feature]
                subset.plot.kde(ax=ax, linewidth=2)
            
            ax.set_title(f'üìà Ph√¢n b·ªë {feature}', fontweight='bold')
            ax.set_xlabel(feature)
            ax.set_ylabel('M·∫≠t ƒë·ªô')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Box plot ƒë·ªÉ so s√°nh ph√¢n b·ªë
        plt.figure(figsize=(15, 10))
        
        for i, feature in enumerate(features, 1):
            plt.subplot(2, 2, i)
            sns.boxplot(data=self.df, x='Species', y=feature)
            plt.title(f'üì¶ Box Plot - {feature}', fontweight='bold')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Violin plot
        plt.figure(figsize=(15, 10))
        
        for i, feature in enumerate(features, 1):
            plt.subplot(2, 2, i)
            sns.violinplot(data=self.df, x='Species', y=feature)
            plt.title(f'üéª Violin Plot - {feature}', fontweight='bold')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def correlation_analysis(self):
        """Ph√¢n t√≠ch t∆∞∆°ng quan"""
        print("\n" + "="*50)
        print("üîó PH√ÇN T√çCH T∆Ø∆†NG QUAN")
        print("="*50)
        
        # Lo·∫°i b·ªè c·ªôt Id
        features = [col for col in self.numeric_features if col != 'Id']
        
        # Ma tr·∫≠n t∆∞∆°ng quan
        correlation_matrix = self.df[features].corr()
        
        # Heatmap t∆∞∆°ng quan
        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
        sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', 
                   center=0, square=True, fmt='.3f')
        plt.title('üîó Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c ƒë·∫∑c tr∆∞ng', fontweight='bold')
        plt.tight_layout()
        plt.show()
        
        # Scatter plot matrix
        print("\nüìä T·∫°o scatter plot matrix...")
        sns.pairplot(self.df, hue='Species', diag_kind='kde', 
                    vars=features, palette='husl')
        plt.suptitle('üîó Scatter Plot Matrix', y=1.02, fontsize=16, fontweight='bold')
        plt.show()
        
        # T∆∞∆°ng quan v·ªõi target
        print("\nüìà T∆∞∆°ng quan v·ªõi lo√†i:")
        for feature in features:
            # T√≠nh correlation cho t·ª´ng lo√†i
            correlations = {}
            for species in self.df['Species'].unique():
                subset = self.df[self.df['Species'] == species]
                if len(subset) > 1:
                    corr = subset[features].corr()[feature].abs().mean()
                    correlations[species] = corr
            
            print(f"  {feature}: {correlations}")
    
    def outlier_analysis(self):
        """Ph√¢n t√≠ch outliers"""
        print("\n" + "="*50)
        print("üîç PH√ÇN T√çCH OUTLIERS")
        print("="*50)
        
        features = [col for col in self.numeric_features if col != 'Id']
        
        # Z-score method
        print("\nüìä Ph√°t hi·ªán outliers b·∫±ng Z-score:")
        for feature in features:
            z_scores = np.abs(stats.zscore(self.df[feature]))
            outliers = self.df[z_scores > 3]
            print(f"  {feature}: {len(outliers)} outliers (Z-score > 3)")
        
        # IQR method
        print("\nüìä Ph√°t hi·ªán outliers b·∫±ng IQR:")
        for feature in features:
            Q1 = self.df[feature].quantile(0.25)
            Q3 = self.df[feature].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = self.df[(self.df[feature] < lower_bound) | (self.df[feature] > upper_bound)]
            print(f"  {feature}: {len(outliers)} outliers (IQR method)")
        
        # Visualize outliers
        plt.figure(figsize=(15, 10))
        
        for i, feature in enumerate(features, 1):
            plt.subplot(2, 2, i)
            
            # Box plot v·ªõi outliers
            sns.boxplot(data=self.df, x='Species', y=feature)
            plt.title(f'üì¶ Outliers - {feature}', fontweight='bold')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def statistical_tests(self):
        """Ki·ªÉm ƒë·ªãnh th·ªëng k√™"""
        print("\n" + "="*50)
        print("üìä KI·ªÇM ƒê·ªäNH TH·ªêNG K√ä")
        print("="*50)
        
        features = [col for col in self.numeric_features if col != 'Id']
        species_list = self.df['Species'].unique()
        
        print("\nüî¨ Ki·ªÉm ƒë·ªãnh ANOVA (so s√°nh trung b√¨nh gi·ªØa c√°c lo√†i):")
        for feature in features:
            groups = [self.df[self.df['Species'] == species][feature].values 
                     for species in species_list]
            f_stat, p_value = stats.f_oneway(*groups)
            print(f"  {feature}: F-statistic={f_stat:.4f}, p-value={p_value:.4f}")
        
        print("\nüî¨ Ki·ªÉm ƒë·ªãnh t√≠nh chu·∫©n (Shapiro-Wilk):")
        for feature in features:
            for species in species_list:
                subset = self.df[self.df['Species'] == species][feature]
                stat, p_value = stats.shapiro(subset)
                print(f"  {feature} - {species}: W={stat:.4f}, p-value={p_value:.4f}")
        
        print("\nüî¨ Ki·ªÉm ƒë·ªãnh t√≠nh ƒë·ªìng nh·∫•t ph∆∞∆°ng sai (Levene):")
        for feature in features:
            groups = [self.df[self.df['Species'] == species][feature].values 
                     for species in species_list]
            stat, p_value = stats.levene(*groups)
            print(f"  {feature}: W={stat:.4f}, p-value={p_value:.4f}")
    
    def dimensionality_reduction(self):
        """Gi·∫£m chi·ªÅu d·ªØ li·ªáu"""
        print("\n" + "="*50)
        print("üìâ GI·∫¢M CHI·ªÄU D·ªÆ LI·ªÜU (PCA)")
        print("="*50)
        
        features = [col for col in self.numeric_features if col != 'Id']
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(self.df[features])
        
        # PCA
        pca = PCA()
        X_pca = pca.fit_transform(X_scaled)
        
        # Explained variance ratio
        print("\nüìä T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch:")
        for i, ratio in enumerate(pca.explained_variance_ratio_):
            print(f"  PC{i+1}: {ratio:.4f} ({ratio*100:.2f}%)")
        
        # Cumulative explained variance
        cumulative_var = np.cumsum(pca.explained_variance_ratio_)
        print(f"\nüìà T·ª∑ l·ªá ph∆∞∆°ng sai t√≠ch l≈©y:")
        for i, var in enumerate(cumulative_var):
            print(f"  PC1-PC{i+1}: {var:.4f} ({var*100:.2f}%)")
        
        # Visualize PCA
        plt.figure(figsize=(15, 5))
        
        # Scree plot
        plt.subplot(1, 3, 1)
        plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), 
                pca.explained_variance_ratio_, 'bo-')
        plt.xlabel('Principal Component')
        plt.ylabel('Explained Variance Ratio')
        plt.title('üìä Scree Plot', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # Cumulative variance
        plt.subplot(1, 3, 2)
        plt.plot(range(1, len(cumulative_var) + 1), cumulative_var, 'ro-')
        plt.xlabel('Principal Component')
        plt.ylabel('Cumulative Explained Variance')
        plt.title('üìà Cumulative Variance', fontweight='bold')
        plt.grid(True, alpha=0.3)
        
        # PCA scatter plot
        plt.subplot(1, 3, 3)
        for species in self.df['Species'].unique():
            mask = self.df['Species'] == species
            plt.scatter(X_pca[mask, 0], X_pca[mask, 1], label=species, alpha=0.7)
        
        plt.xlabel('Principal Component 1')
        plt.ylabel('Principal Component 2')
        plt.title('üîó PCA Scatter Plot', fontweight='bold')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Feature importance in PCA
        print("\nüìä ƒê√≥ng g√≥p c·ªßa t·ª´ng feature trong PCA:")
        for i, feature in enumerate(features):
            print(f"  {feature}: PC1={pca.components_[0, i]:.4f}, PC2={pca.components_[1, i]:.4f}")
    
    def advanced_visualizations(self):
        """Bi·ªÉu ƒë·ªì n√¢ng cao"""
        print("\n" + "="*50)
        print("üé® BI·ªÇU ƒê·ªí N√ÇNG CAO")
        print("="*50)
        
        features = [col for col in self.numeric_features if col != 'Id']
        
        # 3D scatter plot
        fig = plt.figure(figsize=(15, 5))
        
        # 3D scatter v·ªõi 3 features ƒë·∫ßu
        ax1 = fig.add_subplot(131, projection='3d')
        for species in self.df['Species'].unique():
            mask = self.df['Species'] == species
            ax1.scatter(self.df[mask][features[0]], 
                       self.df[mask][features[1]], 
                       self.df[mask][features[2]], 
                       label=species, alpha=0.7)
        
        ax1.set_xlabel(features[0])
        ax1.set_ylabel(features[1])
        ax1.set_zlabel(features[2])
        ax1.set_title('üåê 3D Scatter Plot', fontweight='bold')
        ax1.legend()
        
        # Hexbin plot
        ax2 = fig.add_subplot(132)
        for species in self.df['Species'].unique():
            mask = self.df['Species'] == species
            ax2.hexbin(self.df[mask][features[0]], 
                      self.df[mask][features[1]], 
                      alpha=0.7, label=species)
        
        ax2.set_xlabel(features[0])
        ax2.set_ylabel(features[1])
        ax2.set_title('üî∑ Hexbin Plot', fontweight='bold')
        ax2.legend()
        
        # Joint plot
        ax3 = fig.add_subplot(133)
        for species in self.df['Species'].unique():
            mask = self.df['Species'] == species
            ax3.scatter(self.df[mask][features[2]], 
                       self.df[mask][features[3]], 
                       alpha=0.7, label=species)
        
        ax3.set_xlabel(features[2])
        ax3.set_ylabel(features[3])
        ax3.set_title('üîó Joint Plot', fontweight='bold')
        ax3.legend()
        
        plt.tight_layout()
        plt.show()
        
        # Facet grid
        g = sns.FacetGrid(self.df, col="Species", height=4, aspect=1.2)
        g.map_dataframe(sns.scatterplot, x=features[0], y=features[1], alpha=0.7)
        g.set_titles(col_template="{col_name}")
        g.fig.suptitle('üîç Facet Grid by Species', fontsize=16, fontweight='bold')
        plt.show()
        
        # Swarm plot
        plt.figure(figsize=(15, 10))
        
        for i, feature in enumerate(features, 1):
            plt.subplot(2, 2, i)
            sns.swarmplot(data=self.df, x='Species', y=feature)
            plt.title(f'üêù Swarm Plot - {feature}', fontweight='bold')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
    
    def summary_statistics(self):
        """Th·ªëng k√™ t√≥m t·∫Øt theo lo√†i"""
        print("\n" + "="*50)
        print("üìä TH·ªêNG K√ä T√ìM T·∫ÆT THEO LO√ÄI")
        print("="*50)
        
        features = [col for col in self.numeric_features if col != 'Id']
        
        # Th·ªëng k√™ theo lo√†i
        summary = self.df.groupby('Species')[features].agg([
            'count', 'mean', 'std', 'min', 'max', 'median'
        ]).round(3)
        
        print("\nüìà Th·ªëng k√™ chi ti·∫øt theo lo√†i:")
        print(summary)
        
        # Visualize summary
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('üìä Th·ªëng k√™ theo lo√†i', fontsize=16, fontweight='bold')
        
        for i, feature in enumerate(features):
            row, col = i // 2, i % 2
            ax = axes[row, col]
            
            # Mean v·ªõi error bars
            means = self.df.groupby('Species')[feature].mean()
            stds = self.df.groupby('Species')[feature].std()
            
            bars = ax.bar(means.index, means.values, yerr=stds.values, 
                         capsize=5, alpha=0.7)
            ax.set_title(f'üìä {feature} - Mean ¬± Std', fontweight='bold')
            ax.set_ylabel(feature)
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3)
            
            # Add value labels
            for bar, mean_val in zip(bars, means.values):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{mean_val:.2f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.show()
    
    def run_complete_analysis(self):
        """Ch·∫°y ph√¢n t√≠ch to√†n di·ªán"""
        if not self.load_data():
            return
        
        # Th·ª±c hi·ªán c√°c ph√¢n t√≠ch
        self.basic_info()
        self.distribution_analysis()
        self.correlation_analysis()
        self.outlier_analysis()
        self.statistical_tests()
        self.dimensionality_reduction()
        self.advanced_visualizations()
        self.summary_statistics()
        
        print("\n" + "="*80)
        print("‚úÖ PH√ÇN T√çCH D·ªÆ LI·ªÜU HO√ÄN TH√ÄNH!")
        print("="*80)
        print("\nüìã T√ìM T·∫ÆT K·∫æT QU·∫¢:")
        print("  ‚Ä¢ D·ªØ li·ªáu c√≥ 150 m·∫´u v·ªõi 4 ƒë·∫∑c tr∆∞ng s·ªë")
        print("  ‚Ä¢ 3 lo√†i hoa ƒë∆∞·ª£c ph√¢n b·ªë ƒë·ªÅu (50 m·∫´u m·ªói lo√†i)")
        print("  ‚Ä¢ Kh√¥ng c√≥ missing values")
        print("  ‚Ä¢ C√°c ƒë·∫∑c tr∆∞ng c√≥ t∆∞∆°ng quan m·∫°nh v·ªõi nhau")
        print("  ‚Ä¢ PCA cho th·∫•y 2 th√†nh ph·∫ßn ch√≠nh gi·∫£i th√≠ch >95% ph∆∞∆°ng sai")
        print("  ‚Ä¢ D·ªØ li·ªáu ph√π h·ª£p cho machine learning")

def main():
    """H√†m ch√≠nh"""
    analyzer = ComprehensiveDataAnalysis()
    analyzer.run_complete_analysis()

if __name__ == "__main__":
    main() 